---
layout: post
title: "Uncovering the Intriguing Properties of Vision Transformers: Insights and Applications"
---

<h5>
    Chanyoung Kim - MICV Lab, AI, Yonsei University
</h5>

Vision Transformers (ViTs) have become prominent models in computer vision, offering competitive performance across a variety of tasks. Beyond their effectiveness, ViTs exhibit a range of interesting and non-obvious characteristics. For example, different layers capture varying types of information, each contributing uniquely to the overall representation. Furthermore, attention patterns show that some image patches focus more on local features, while others prioritize global contextâ€”even within a single input. These observations point to an organized yet adaptable way in which ViTs handle visual information.
In this seminar, we examine these hidden properties of ViTs through empirical findings and theoretical perspectives. We also explore how a deeper understanding of such characteristics can inform the design of downstream applications. By investigating the internal workings of ViTs, we aim to provide insights that can lead to more effective and targeted use of transformer-based models in visual learning tasks.

[PPT](https://drive.google.com/file/d/12wMY23v3Rb7MyxGwmzkm8qXHaG0OZN77/view?usp=share_link)
[CV](https://kochanha.github.io/)

<i>
    Catering Courtesy of <a href="https://sites.google.com/view/asolabysu/home">ASO Lab</a>
</i>