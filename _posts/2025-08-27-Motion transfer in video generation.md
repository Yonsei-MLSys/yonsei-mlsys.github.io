---
layout: post
title: "Motion transfer in video generation"
---

<h5>
    Sunyoung Jung - MICV, AI, Yonsei University
</h5>

This presentation explore the task of motion transfer for video generation, which aims to generate a new video by combining a text prompt with motion from a reference video. A key challenge in this domain is to accurately extract motion dynamics from the reference video while excluding visual elements such as appearance and background. To address this, novel frameworks have been proposed that effectively extract a motion-specific representation and fuse it with semantic information derived from the text prompt. This talk will analyze the techniques these papers employ to achieve a robust motion-specific representation. The goal is to provide a comprehensive overview and offer insights into promising future directions for controllable video synthesis.

[PPT](https://docs.google.com/presentation/d/1tdgyQIrpln8T40XEXLOpJhCuF6kKupse/edit?usp=sharing&ouid=111948851444227468135&rtpof=true&sd=true)
[CV](https://drive.google.com/file/d/1sf66FNQarbcGMSQPX_3tyhF0tX5r6k7C/view?usp=sharing)

<i>
    Catering Courtesy of <a href="https://albert-no.github.io/">AI-ISL</a>
</i>