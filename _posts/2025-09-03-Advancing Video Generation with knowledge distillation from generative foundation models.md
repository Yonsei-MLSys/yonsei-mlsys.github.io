---
layout: post
title: "Advancing Video Generation with knowledge distillation from generative foundation models"
---

<h5>
    Sejong Yang - CIP Lab, CS, Yonsei University
</h5>

This paper explains that while traditional computer vision has focused on reassembling or transforming existing video data, modern video generation enables the creation of novel and realistic content by utilizing generative models such as GANs, VAEs, and diffusion models to learn implicit representations of appearance and motion from large-scale datasets, and presents a research objective of enhancing the feasibility of deploying video generation in real-time interactive systems by developing lightweight architectures that maintain fidelity and expressiveness while enabling practical runtime performance through knowledge distillation from generative foundation models to address the high computational costs and data-intensive characteristics of high-quality video generation.

[PPT](https://docs.google.com/presentation/d/1ioAw2NDQ3w7OL7URhZuvEO64V6LK86hU/edit?usp=sharing&ouid=111948851444227468135&rtpof=true&sd=true)
[CV](https://yangspace.co.kr/)

<i>
    Catering Courtesy of <a href="https://sites.google.com/view/asolabysu/home">ASO Lab</a>
</i>
