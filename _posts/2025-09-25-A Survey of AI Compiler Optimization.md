---
layout: post
title: "A Survey of AI Compiler Optimization"
---

<h5>
    Kiung Jung - ASO Lab, CS, Yonsei University
</h5>

This talk surveys how modern AI compilers optimize deep-learning workloads, starting from a comparison between PyTorchâ€™s eager execution and graph mode and how each affects dispatch, fusion, and specialization.
Graph capture is highlighted as a key enabler for global optimizations that are difficult in purely eager environments.
The rising interest in domain-specific languages (DSLs) for tensor computation is then introduced.
Major DSL, including Triton, Helion, and Cute DSL, are outlined.
The talk concludes with a summary of the optimizations each DSL family aims to automate, including fusion, tiling, memory scheduling, layout transformations, and hardware-specialized kernel generation.

[PPT](https://docs.google.com/presentation/d/1JvtYGBSb-Bpp3kYl4V7C4ejLh3V4CbMHrO_JycpvfeA/edit?usp=sharing)
[CV](https://quqqu.github.io/curriculum-vitae/)

<i>
    Catering Courtesy of <a href="https://micv.yonsei.ac.kr/">MICV Lab</a>
</i>
